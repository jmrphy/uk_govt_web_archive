# Plot 2, more sci-fi and with no vertex labels
par(bg="gray15", mar=c(1,1,1,1))
plot(rt_graph, layout=glay,
vertex.color=hsv(h=.35, s=1, v=.7, alpha=0.1),
vertex.frame.color=hsv(h=.35, s=1, v=.7, alpha=0.1),
vertex.size=5,
vertex.label=NA,
vertex.label.family="mono",
vertex.label.color=hsv(h=0, s=0, v=.95, alpha=0.5),
vertex.label.cex=0.85,
edge.arrow.size=0.8,
edge.arrow.width=0.5,
edge.width=3,
edge.color=hsv(h=.35, s=1, v=.7, alpha=0.4))
title("Retweet Network at #PSA14",
cex.main=1, col.main="gray95", family="mono")
cent<-data.frame(bet=betweenness(rt_graph),eig=evcent(rt_graph)$vector)
res<-lm(eig~bet,data=cent)$residuals
cent<-transform(cent,res=res)
library(ggplot2)
p<-ggplot(cent,aes(x=bet,y=eig,
label=rownames(cent),colour=res,
size=abs(res)))+
xlab("Betweenness Centrality")+ylab("Eigenvector Centrality")
p+geom_text()+opts(title="Key Actor Analysis for #PSA14")
cent<-data.frame(bet=betweenness(rt_graph),eig=evcent(rt_graph)$vector)
res<-lm(eig~bet,data=cent)$residuals
cent<-transform(cent,res=res)
library(ggplot2)
p<-ggplot(cent,aes(x=bet,y=eig,
label=rownames(cent),colour=res))+
xlab("Betweenness Centrality")+ylab("Eigenvector Centrality")
p+geom_text()+opts(title="Key Actor Analysis for #PSA14")
library(rstan)
install.packages("rstan")
rstan
??rstan
require(rstan)
install.packages('inline')
install.packages('Rcpp')
library(inline)
library(Rcpp)
src <- '
std::vector<std::string> s;
s.push_back("hello");
s.push_back("world");
return Rcpp::wrap(s);
'
hellofun <- cxxfunction(body = src, includes = '', plugin = 'Rcpp', verbose = FALSE)
cat(hellofun(), '\n')
options(repos = c(getOption("repos"), rstan = "http://wiki.rstan-repo.googlecode.com/git/"))
install.packages('rstan', type = 'source')
gc()
source("~/Dropbox/gh_projects/uk_govt_web_archive/analyses/cluster_diagnose_k.R")
source("~/Dropbox/gh_projects/uk_govt_web_archive/analyses/cluster_diagnose_k.R")
grid.arrange(wss.plot, sse.plot)
load("~/Dropbox/gh_projects/uk_govt_web_archive/data/k_clusters.Rdata")
load("~/Dropbox/gh_projects/uk_govt_web_archive/data/globalisation_dtm.Rdata")
load("~/Dropbox/gh_projects/uk_govt_web_archive/data/globalisation_corpus.Rdata")
kclusters<-kmeans(kdata, centers=5)
kclusters
summary(kclusters)
table(cl$cluster)
table(kclusters$cluster)
plot(prcomp(m_norm)$x, col=kclusters$cl)
findFreqTerms(kdata[kclusters$cluster==1], 50)
findFreqTerms(dtm[kclusters$cluster==1], 50)
sampledtm<-standarddtm[sample(nrow(standarddtm),size=(dim(standarddtm)[1]/70),replace=FALSE),]
rowtotals <- apply(dtm, 1, sum) # find the sum of words in each document
standarddtm <- dtm/rowtotals  # Thanks to Brandon Stewart for this and the code below here http://faculty.washington.edu/jwilker/tft/Stewart.LabHandout.pdf
sampledtm<-standarddtm[sample(nrow(standarddtm),size=(dim(standarddtm)[1]/70),replace=FALSE),]
findFreqTerms(sampledtm[kclusters$cluster==1], 50)
require(tm)
findFreqTerms(sampledtm[kclusters$cluster==1], 50)
kclusters$cluster==1
findFreqTerms(kdata[kclusters$cluster==1], 50)
findFreqTerms(dtm[kclusters$cluster==1], 50)
findFreqTerms(standarddtm[kclusters$cluster==1], 50)
findFreqTerms(sampledtm[kclusters$cluster==1], 50)
inspect(reuters[which(cl$cluster==1)])
inspect(dtm[which(kclusters$cluster==1)])
inspect(kdata[which(kclusters$cluster==1)])
dim(sampledtm) # check, reduced
dim(kdata)
sampledtm[kclusters$cluster==1]
sampledtm[kclusters$cluster==1]
sampledtm[,kclusters$cluster==1]
findFreqTerms(sampledtm[,kclusters$cluster==1], 50)
findFreqTerms(sampledtm[kclusters$cluster==1,], 50)
sampledtm[kclusters$cluster==1,]
sampledtm[[kclusters$cluster==1,]]
sampledtm[[kclusters$cluster==1]]
sampledtm[kclusters$cluster==2]
kclusters$cluster
<-kclusters$clusters[kclusters$cluster==1]
kclusters$clusters[kclusters$cluster==1]
kclusters[kclusters$cluster==1]
kclusters[kclusters$cluster==2]
kclusters$clusters
names(kclusters)
kclusters$cluster
kclusters[kclusters$cluster==2]
findFreqTerms(sampledtm[kclusters$cluster==1], 50)
findFreqTerms(sampledtm[1][kclusters$cluster==1], 50)
sampledtm[1]
require(tm)
sampledtm[1]
sampledtm[[1]]
findFreqTerms(sampledtm[[1]][kclusters$cluster==1], 50)
table(kclusters$cluster)
summary(kclusters)
load("data/globalisation_dtm.Rdata")
rowtotals <- apply(dtm, 1, sum) # find the sum of words in each document
standarddtm <- dtm/rowtotals  # Thanks to Brandon Stewart for this and the code below here http://faculty.washington.edu/jwilker/tft/Stewart.LabHandout.pdf
sampledtm<-standarddtm[sample(nrow(standarddtm),size=(dim(standarddtm)[1]/70),replace=FALSE),]
rm(dtm)
dim(sampledtm) # check, reduced
### Use euclidean distances
m <- as.matrix(sampledtm)
rownames(m) <- 1:nrow(m)
load("data/globalisation_dtm.Rdata")
setwd("~/Dropbox/gh_projects/uk_govt_web_archive")
load("data/globalisation_dtm.Rdata")
rowtotals <- apply(dtm, 1, sum) # find the sum of words in each document
standarddtm <- dtm/rowtotals  # Thanks to Brandon Stewart for this and the code below here http://faculty.washington.edu/jwilker/tft/Stewart.LabHandout.pdf
sampledtm<-standarddtm[sample(nrow(standarddtm),size=(dim(standarddtm)[1]/70),replace=FALSE),]
rm(dtm)
dim(sampledtm) # check, reduced
### Use euclidean distances
m <- as.matrix(sampledtm)
rownames(m) <- 1:nrow(m)
norm_eucl <- function(m) m/apply(m, MARGIN=1, FUN=function(x) sum(x^2)^.5)
m_norm <- norm_eucl(m)
kdata <- norm_eucl(m)
sampledtm<-standarddtm[sample(nrow(standarddtm),size=(dim(standarddtm)[1]/50),replace=FALSE),]
rm(dtm)
dim(sampledtm) # check, reduced
sampledtm<-standarddtm[sample(nrow(standarddtm),size=(dim(standarddtm)[1]/50),replace=FALSE),]
rm(dtm)
dim(sampledtm) # check, reduced
### Use euclidean distances
m <- as.matrix(sampledtm)
rownames(m) <- 1:nrow(m)
### don't forget to normalize the vectors so Euclidean makes sense
norm_eucl <- function(m) m/apply(m, MARGIN=1, FUN=function(x) sum(x^2)^.5)
kdata <- norm_eucl(m)
set.seed(666)
n.lev<-100
wss <- rnorm(10)
while (prod(wss==sort(wss,decreasing=T))==0) {
wss <- (nrow(kdata)-1)*sum(apply(kdata,2,var))
for (i in c(2,3,4,5,10,50,100)) wss[i] <- sum(kmeans(kdata, centers=i)$withinss)}
k<-c(2,3,4,5,10,50,100)
wss <- rnorm(10)
while (prod(wss==sort(wss,decreasing=T))==0) {
wss <- (nrow(kdata)-1)*sum(apply(kdata,2,var))
for (i in k) wss[i] <- sum(kmeans(kdata, centers=i)$withinss)}
wss <- rnorm(10)
k<-c(2,3,4,5,10,50)
wss <- rnorm(10)
while (prod(wss==sort(wss,decreasing=T))==0) {
wss <- (nrow(kdata)-1)*sum(apply(kdata,2,var))
for (i in k) wss[i] <- sum(kmeans(kdata, centers=i)$withinss)}
wss
wss <- rnorm(100)
wss
wss <- rnorm(10)
wss
k<-c(2,3,4,5,10,50,100)
wss <- rnorm(100)
while (prod(wss==sort(wss,decreasing=T))==0) {
wss <- (nrow(kdata)-1)*sum(apply(kdata,2,var))
for (i in k) wss[i] <- sum(kmeans(kdata, centers=i)$withinss)}
wss
set.seed(666)
n.lev<-20
wss <- rnorm(10)
while (prod(wss==sort(wss,decreasing=T))==0) {
wss <- (nrow(kdata)-1)*sum(apply(kdata,2,var))
for (i in 2:n.lev) wss[i] <- sum(kmeans(kdata, centers=i)$withinss)}
k.rand <- function(x){
km.rand <- matrix(sample(x),dim(x)[1],dim(x)[2])
rand.wss <- as.matrix(dim(x)[1]-1)*sum(apply(km.rand,2,var))
for (i in 2:n.lev) rand.wss[i] <- sum(kmeans(km.rand, centers=i)$withinss)
rand.wss <- as.matrix(rand.wss)
return(rand.wss)}
rand.mat <- matrix(0,n.lev,250)
k.1 <- function(x) {
for (i in 1:250) {
r.mat <- as.matrix(suppressWarnings(k.rand(kdata)))
rand.mat[,i] <- r.mat}
return(rand.mat)}
rand.mat <- k.1(kdata)
rand.mat
r.sse <- matrix(0,dim(rand.mat)[1],dim(rand.mat)[2])
wss.1 <- as.matrix(wss)
for (i in 1:dim(r.sse)[2]) {
r.temp <- abs(rand.mat[,i]-wss.1[,1])
r.sse[,i] <- r.temp}
r.sse.m <- apply(r.sse,1,mean)
r.sse.sd <- apply(r.sse,1,sd)
r.sse.plus <- r.sse.m + r.sse.sd
r.sse.min <- r.sse.m - r.sse.sd
K<-1:n.lev
sse<-data.frame(K, r.sse.plus, r.sse.m, r.sse.min)
sse<-melt(sse, id="K")
sse.plot<-ggplot(sse, aes(x=K, y=value, colour=variable)) +
geom_line() +
theme_bw() +
theme(legend.position = "none") +
labs(y="Absolute Difference of Sum of Squared Error", x="Clusters (k)", title="Difference of Error Between Random and Actual Data by K") +
scale_color_manual(values=c("#000000","#CC6666", "#000000"))
sse.plot
n.lev<-20
K<-1:n.lev
wss.df<-data.frame(wss,1:n.lev)
names(wss.df)<-c("WSS", "K")
wss.plot<-ggplot(wss.df, aes(x=K, y=WSS)) +
geom_line() +
theme_bw() +
labs(y="Within Sum of Squares", x="Clusters (k)", title="Within Sum of Squares by Number of Clusters")
wss.plot
sse.plot
wss.plot
sse.plot
sse.plot
wss.plot
wss.plot<-ggplot(wss.df, aes(x=K, y=WSS)) +
geom_line() +
theme_bw() +
labs(y="Within Sum of Squares", x="Clusters (k)", title="Within Sum of Squares by Number of Clusters")
sse.plot<-ggplot(sse, aes(x=K, y=value, colour=variable)) +
geom_line() +
theme_bw() +
theme(legend.position = "none") +
labs(y="Absolute Difference of Sum of Squared Error", x="Clusters (k)", title="Difference of Error Between Random and Actual Data by K") +
scale_color_manual(values=c("#000000","#CC6666", "#000000"))
wss.plot
sse.plot
n.lev<-20
K<-1:n.lev
wss.df<-data.frame(wss,1:n.lev)
names(wss.df)<-c("WSS", "K")
wss.plot<-ggplot(wss.df, aes(x=K, y=WSS)) +
geom_line() +
theme_bw() +
labs(y="Within Sum of Squares", x="Clusters (k)", title="Within Sum of Squares by Number of Clusters")
wss.plot
r.sse <- matrix(0,dim(rand.mat)[1],dim(rand.mat)[2])
wss.1 <- as.matrix(wss)
for (i in 1:dim(r.sse)[2]) {
r.temp <- abs(rand.mat[,i]-wss.1[,1])
r.sse[,i] <- r.temp}
r.sse.m <- apply(r.sse,1,mean)
r.sse.sd <- apply(r.sse,1,sd)
r.sse.plus <- r.sse.m + r.sse.sd
r.sse.min <- r.sse.m - r.sse.sd
K<-1:n.lev
sse<-data.frame(K, r.sse.plus, r.sse.m, r.sse.min)
sse<-melt(sse, id="K")
sse.plot<-ggplot(sse, aes(x=K, y=value, colour=variable)) +
geom_line() +
theme_bw() +
theme(legend.position = "none") +
labs(y="Absolute Difference of Sum of Squared Error", x="Clusters (k)", title="Difference of Error Between Random and Actual Data by K") +
scale_color_manual(values=c("#000000","#CC6666", "#000000"))
sse.plot
save(wss, kdata, rand.mat, sampledtm, file="data/k_clusters.Rdata")
rand.mat <- k.1(kdata)
rand.mat
wss
sampledtm<-standarddtm[sample(nrow(standarddtm),size=(dim(standarddtm)[1]/45),replace=FALSE),]
rm(dtm)
dim(sampledtm) # check, reduced
### Use euclidean distances
m <- as.matrix(sampledtm)
rownames(m) <- 1:nrow(m)
### don't forget to normalize the vectors so Euclidean makes sense
norm_eucl <- function(m) m/apply(m, MARGIN=1, FUN=function(x) sum(x^2)^.5)
kdata <- norm_eucl(m)
# Calculate the within groups sum of squared error (SSE) for the number of cluster solutions selected by the user
set.seed(666)
n.lev<-30
wss <- rnorm(10)
while (prod(wss==sort(wss,decreasing=T))==0) {
wss <- (nrow(kdata)-1)*sum(apply(kdata,2,var))
for (i in 2:n.lev) wss[i] <- sum(kmeans(kdata, centers=i)$withinss)}
sampledtm<-standarddtm[sample(nrow(standarddtm),size=(dim(standarddtm)[1]/50),replace=FALSE),]
rm(dtm)
dim(sampledtm) # check, reduced
### Use euclidean distances
m <- as.matrix(sampledtm)
rownames(m) <- 1:nrow(m)
### don't forget to normalize the vectors so Euclidean makes sense
norm_eucl <- function(m) m/apply(m, MARGIN=1, FUN=function(x) sum(x^2)^.5)
kdata <- norm_eucl(m)
# Calculate the within groups sum of squared error (SSE) for the number of cluster solutions selected by the user
set.seed(666)
n.lev<-30
wss <- rnorm(10)
while (prod(wss==sort(wss,decreasing=T))==0) {
wss <- (nrow(kdata)-1)*sum(apply(kdata,2,var))
for (i in 2:n.lev) wss[i] <- sum(kmeans(kdata, centers=i)$withinss)}
wss
n.lev<-30
K<-1:n.lev
wss.df<-data.frame(wss,1:n.lev)
warnings()
wss
n.lev<-28
K<-1:n.lev
wss.df<-data.frame(wss,1:n.lev)
names(wss.df)<-c("WSS", "K")
wss.plot<-ggplot(wss.df, aes(x=K, y=WSS)) +
geom_line() +
theme_bw() +
labs(y="Within Sum of Squares", x="Clusters (k)", title="Within Sum of Squares by Number of Clusters")
wss.plot
k.rand <- function(x){
km.rand <- matrix(sample(x),dim(x)[1],dim(x)[2])
rand.wss <- as.matrix(dim(x)[1]-1)*sum(apply(km.rand,2,var))
for (i in 2:n.lev) rand.wss[i] <- sum(kmeans(km.rand, centers=i)$withinss)
rand.wss <- as.matrix(rand.wss)
return(rand.wss)}
rand.mat <- matrix(0,n.lev,250)
k.1 <- function(x) {
for (i in 1:250) {
r.mat <- as.matrix(suppressWarnings(k.rand(kdata)))
rand.mat[,i] <- r.mat}
return(rand.mat)}
rand.mat <- k.1(kdata)
rand.mat
n.lev<-28
K<-1:n.lev
wss.df<-data.frame(wss,1:n.lev)
names(wss.df)<-c("WSS", "K")
wss.plot<-ggplot(wss.df, aes(x=K, y=WSS)) +
geom_line() +
theme_bw() +
labs(y="Within Sum of Squares", x="Clusters (k)", title="Within Sum of Squares by Number of Clusters")
wss.plot
r.sse <- matrix(0,dim(rand.mat)[1],dim(rand.mat)[2])
wss.1 <- as.matrix(wss)
for (i in 1:dim(r.sse)[2]) {
r.temp <- abs(rand.mat[,i]-wss.1[,1])
r.sse[,i] <- r.temp}
r.sse.m <- apply(r.sse,1,mean)
r.sse.sd <- apply(r.sse,1,sd)
r.sse.plus <- r.sse.m + r.sse.sd
r.sse.min <- r.sse.m - r.sse.sd
K<-1:n.lev
sse<-data.frame(K, r.sse.plus, r.sse.m, r.sse.min)
sse<-melt(sse, id="K")
sse.plot<-ggplot(sse, aes(x=K, y=value, colour=variable)) +
geom_line() +
theme_bw() +
theme(legend.position = "none") +
labs(y="Absolute Difference of Sum of Squared Error", x="Clusters (k)", title="Difference of Error Between Random and Actual Data by K") +
scale_color_manual(values=c("#000000","#CC6666", "#000000"))
sse.plot
sse<-data.frame(K, r.sse.plus, r.sse.m, r.sse.min)
sse
sse.plot<-ggplot(sse, aes(x=K, y=value, colour=variable)) +
geom_line() +
theme_bw() +
#  theme(legend.position = "none") +
labs(y="Absolute Difference of Sum of Squared Error", x="Clusters (k)", title="Difference of Error Between Random and Actual Data by K") +
scale_color_manual(values=c("#000000","#CC6666", "#000000"))
sse.plot
sse<-melt(sse, id="K")
sse.plot<-ggplot(sse, aes(x=K, y=value, colour=variable)) +
geom_line() +
theme_bw() +
#  theme(legend.position = "none") +
labs(y="Absolute Difference of Sum of Squared Error", x="Clusters (k)", title="Difference of Error Between Random and Actual Data by K") +
scale_color_manual(values=c("#000000","#CC6666", "#000000"))
sse.plot
wss.plot
par(ask=TRUE)
xrange <- range(1:n.lev)
yrange <- range(log(rand.mat),log(wss))
plot(xrange,yrange, type='n', xlab='Cluster Solution', ylab='Log of Within Group SSE', main='Cluster Solutions against Log of SSE')
lines(log(wss), type="b", col='blue')
legend('topright',c('Actual Data', '250 Random Runs'), col=c('blue', 'red'), lty=1)
par(ask=TRUE)
yrange <- range(rand.mat,wss)
plot(xrange,yrange, type='n', xlab="Cluster Solution", ylab="Within Groups SSE", main="Cluster Solutions against SSE")
lines(1:n.lev, wss, type="b", col='blue')
legend('topright',c('Actual Data', '250 Random Runs'), col=c('blue', 'red'), lty=1)
wss.plot
?seq
10/0
dim(kdata)
rowtotals <- apply(dtm, 1, sum) # find the sum of words in each document
standarddtm <- dtm/rowtotals  # Thanks to Brandon Stewart for this and the code below here http://faculty.washington.edu/jwilker/tft/Stewart.LabHandout.pdf
sampledtm<-standarddtm[sample(nrow(standarddtm),size=(dim(standarddtm)[1]/50),replace=FALSE),]
rm(dtm)
dim(sampledtm) # check, reduced
### Use euclidean distances
m <- as.matrix(sampledtm)
rownames(m) <- 1:nrow(m)
### don't forget to normalize the vectors so Euclidean makes sense
norm_eucl <- function(m) m/apply(m, MARGIN=1, FUN=function(x) sum(x^2)^.5)
kdata <- norm_eucl(m)
save(wss, kdata, sampledtm, file="data/k_clusters.Rdata")
kclusters<-kmeans(kdata, centers=28)
m <- as.matrix(standarddtm)
rownames(m) <- 1:nrow(m)
norm_eucl <- function(m) m/apply(m, MARGIN=1, FUN=function(x) sum(x^2)^.5)
kdata <- norm_eucl(m)
set.seed(666)
n.lev<-c(20,40,60,80,100,200)
wss <- rnorm(10)
while (prod(wss==sort(wss,decreasing=T))==0) {
wss <- (nrow(kdata)-1)*sum(apply(kdata,2,var))
for (i in n.lev) wss[i] <- sum(kmeans(kdata, centers=i)$withinss)}
wss
n.lev
seq(100,1000,100)
n.lev<-seq(100,1000,100)
wss <- rnorm(10)
wss
set.seed(666)
n.lev<-seq(100,1000,100)
wss <- rnorm(10)
while (prod(wss==sort(wss,decreasing=T))==0) {
wss <- (nrow(kdata)-1)*sum(apply(kdata,2,var))
for (i in n.lev) wss[i] <- sum(kmeans(kdata, centers=i)$withinss)}
wss
wss[!is.na(wss)]
wss.df<-as.data.frame(wss[!is.na(wss)])
View(wss.df)
View(wss.df)
wss.df
save(wss.df, kdata, standarddtm, file="data/k_clusters.Rdata")
load("~/Dropbox/gh_projects/uk_govt_web_archive/data/k_clusters.Rdata")
seq(100,700,100)
seq(100,700,100)
n.lev<-seq(100,700,100)
wss.df<-data.frame(wss,n.lev)
wss.df<-data.frame(wss.df,n.lev)
View(wss.df)
names(wss.df)<-c("WSS", "K")
wss.plot<-ggplot(wss.df, aes(x=K, y=WSS)) +
geom_line() +
theme_bw() +
labs(y="Within Sum of Squares", x="Clusters (k)", title="Within Sum of Squares by Number of Clusters")
wss.plot
load("~/Dropbox/gh_projects/uk_govt_web_archive/data/k_clusters.Rdata")
rm(standarddtm)
load("~/Dropbox/gh_projects/uk_govt_web_archive/data/k_clusters.Rdata")
kclusters<-kmeans(standarddtm, centers=200)
summary(kclusters)
table(kclusters$cluster)
clusterNum <- 1 #Set the Cluster Number you want to look at
standarddtm
standarddtm[1]
load("~/Dropbox/gh_projects/uk_govt_web_archive/data/globalisation_corpus.Rdata")
corpus[1]
corpus[2]
corpus
?meta
meta(corpus)
meta(corpus[1])
corpus[[1]]
meta(corpus[[1]])
heading(corpus[[1]])
names(meta(corpus[[1]]))
meta(corpus[[1]], tag="Heading")
lapply(corpus, function(x) meta(x, tag="Heading"))
corpus[which(results$cluster==clusterNum)]
corpus[which(kclusters$cluster==clusterNum)]
corpus[which(kclusters$cluster==clusterNum)][sample(sum(kclusters$cluster==clusterNum),1)]
inspect(corpus[which(kclusters$cluster==clusterNum)][sample(sum(kclusters$cluster==clusterNum),1)])
meta(corpus[which(kclusters$cluster==clusterNum)][sample(sum(kclusters$cluster==clusterNum),1)], tag="Heading")
meta(corpus[which(kclusters$cluster==clusterNum)][sample(sum(kclusters$cluster==clusterNum),1)], tag="Heading")
meta(corpus[which(kclusters$cluster==clusterNum)][sample(sum(kclusters$cluster==clusterNum),1)])
meta(corpus[which(kclusters$cluster==clusterNum)][sample(sum(kclusters$cluster==clusterNum),1)], tag="heading")
one.corp<-corpus[which(kclusters$cluster==clusterNum)][sample(sum(kclusters$cluster==clusterNum),1)])
inspect(corpus[which(kclusters$cluster==clusterNum)][sample(sum(kclusters$cluster==clusterNum),1)])
corpus[which(kclusters$cluster==clusterNum)][sample(sum(kclusters$cluster==clusterNum),1)])
one.corp<-corpus[which(kclusters$cluster==clusterNum)][sample(sum(kclusters$cluster==clusterNum),1)]
meta(one.corp, tag="Heading")
clusterNum <- 2 #Set the Cluster Number you want to look at
inspect(corpus[which(kclusters$cluster==clusterNum)][sample(sum(kclusters$cluster==clusterNum),1)])
one.corp<-corpus[which(kclusters$cluster==clusterNum)][sample(sum(kclusters$cluster==clusterNum),1)]
meta(one.corp, tag="Heading")
?Corpus
one.corp<-Corpus(one.corp)
inspect(corpus[which(kclusters$cluster==clusterNum)][sample(sum(kclusters$cluster==clusterNum),1)])
meta(corpus[which(kclusters$cluster==clusterNum)][sample(sum(kclusters$cluster==clusterNum),1)])
meta(corpus[which(kclusters$cluster==clusterNum)][sample(sum(kclusters$cluster==clusterNum),1)], tag="Heading")
k<-200
round(kclusters$centers, digits=3)
?meta
?docs
for (i in 1:k) {
cat(paste("cluster ", i, ": ", sep=""))
s <- sort(kclusters$centers[i,], decreasing=T)
cat(names(s)[1:15], "\n")
# print the tweets of every cluster + #
print(corpus[which(kclusters$cluster==i)])
}
load("~/Dropbox/gh_projects/uk_govt_web_archive/data/k_clusters.Rdata")
n.lev<-seq(100,700,100)
wss.df<-data.frame(wss.df,n.lev)
names(wss.df)<-c("WSS", "K")
wss.plot<-ggplot(wss.df, aes(x=K, y=WSS)) +
geom_line() +
theme_bw() +
labs(y="Within Sum of Squares", x="Clusters (k)", title="Within Sum of Squares by Number of Clusters")
wss.plot
